{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9347395f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computer Vision (Winter 2021/22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21261c73",
   "metadata": {},
   "source": [
    "#### Practice Session 7: Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31918b",
   "metadata": {},
   "source": [
    "November 30th, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7c443",
   "metadata": {},
   "source": [
    "Axel Schaffland, Ulf Krumnack\n",
    "\n",
    "Institute of Cognitive Science\n",
    "University of Osnabr√ºck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658a711",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Today's Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e98932",
   "metadata": {},
   "source": [
    "* Questions from last sheet\n",
    "    * [Sheet 1 Assignment 1b](../../sheets/sheet01/sheet01.Rmd):Proof linearity and homogenity\n",
    "        * What exactly are we doing?\n",
    "    * [Sheet 2 Assignment 3c](../../sheets/sheet02/sheet02.Rmd): Adaptive Histogram Equalisation\n",
    "        * Why are the algorithms in the solution more efficient? \n",
    "* New sheet\n",
    "    * Region Growing\n",
    "    * K-Means\n",
    "* Canny Edge    \n",
    "* Mean Shift Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c067b",
   "metadata": {},
   "source": [
    "## Zero Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575fedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../../resources/segmentation/zeroCrossingComplete.pdf\", width=900, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff0588",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "For background information watch Lecture 11 of the Information Theory, Pattern Recognition, and Neural Networks course by the late David MacKay: http://www.inference.org.uk/itprnn_lectures/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d08cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"800\"\n",
       "            src=\"../../resources/segmentation/kmeans.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1cb22f42100>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../../resources/segmentation/kmeans.pdf\", width=900, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5597424",
   "metadata": {},
   "source": [
    "Questions:\n",
    "* Is spacial information relevant?\n",
    "* Local or global solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cca913",
   "metadata": {},
   "source": [
    "## Region Growing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44d4a2",
   "metadata": {},
   "source": [
    "Recursive:\n",
    "```\n",
    "floodfill(img, mask, (x,y), color, region)\n",
    "    if pixel not visited:\n",
    "        mark pixel visited in mask\n",
    "        if pixel value below treshold distance from region color:\n",
    "            add pixel to region\n",
    "            # check if these pixels are inside the image\n",
    "            floodfill(pixel left of current pixel)\n",
    "            floodfill(pixel right of current pixel)\n",
    "            floodfill(pixel top of current pixel)\n",
    "            floodfill(pixel down of current pixel) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d8f02",
   "metadata": {},
   "source": [
    "# Mean Shift Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2035098a",
   "metadata": {},
   "source": [
    "## Comparison of k-means clustering and mean shift\n",
    "\n",
    "k-means | mean shift\n",
    ":---|:---\n",
    "parametric| non-parametric\n",
    "density as a superpostion of simpler distributions | smooth distribution\n",
    "find location (and shape) of simple distributions | find peaks and regions corresponding to peaks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0949b",
   "metadata": {},
   "source": [
    "## Literature\n",
    "\n",
    "* [Richard Szeliski: Computer Vision Algorithms and Applications, Chapter 5.3.2](https://szeliski.org/Book/1stEdition.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8787789",
   "metadata": {},
   "source": [
    "# Implementing mean shift segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d726ea0",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf13af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "\n",
    "class MSS:\n",
    "    \"\"\"A class for performing mean shift segmentation and clustering.\n",
    "    \"\"\"\n",
    "\n",
    "    # sigma_c: the color coefficient\n",
    "    sigma_c = .1  # .05\n",
    "\n",
    "    # minimal change during mean shift step required for continuouing the process\n",
    "    epsilon = .1\n",
    "\n",
    "    # radius: the maximal distance for points in the 5D spatial-range representation\n",
    "    # space to be considered neighbors\n",
    "    radius = 1/10\n",
    "    \n",
    "    # max_dist:\n",
    "    max_dist = .5\n",
    "\n",
    "    # min_elem:\n",
    "    min_elem = 10\n",
    "    \n",
    "    def __init__(self, img, sigma_c=None, epsilon=None, radius=None):\n",
    "        \"\"\"Initialize an MSS object\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        img: np.ndarray\n",
    "        sigma_c: float\n",
    "        epsilon: float\n",
    "        radius: float\n",
    "        \"\"\"\n",
    "        \n",
    "        self.sigma_c = MSS.sigma_c if not sigma_c else sigma_c\n",
    "        self.epsilon = MSS.epsilon if not epsilon else epsilon\n",
    "        self.radius = MSS.radius if not radius else radius\n",
    "        \n",
    "        # self.img: (a copy of) the image to be processed\n",
    "        self.img = img.copy()\n",
    "        self.size_x = self.img.shape[0]\n",
    "        self.size_y = self.img.shape[1]\n",
    "        self.size_z = 3 if self.img.ndim == 3 else 1\n",
    "\n",
    "        # here we scale the spatial coordinates to the real interval [0,1]x[0,1].\n",
    "        yy, xx = np.meshgrid(np.linspace(0, 1, self.img.shape[1]), np.linspace(0, 1, self.img.shape[0]))\n",
    "        yy, xx = np.indices(img.shape[:2])\n",
    "\n",
    "        # self.d: the 5D spatial-range representation: (pixels, 5) storing for each pixel a 5-tupel (x,y,color),\n",
    "        # consisting of the spatial coordinates (x,y) the 3D-color value (e.g., RGB).\n",
    "        self.d = np.empty((self.img.shape[0]*self.img.shape[1], 2 + self.size_z))\n",
    "        self.d[:, 0] = xx.flatten()\n",
    "        self.d[:, 1] = yy.flatten()\n",
    "        self.d[:, 2:] = self.img.reshape(self.img.shape[0]*self.img.shape[1],self.size_z) * self.sigma_c\n",
    "\n",
    "        # self.g_star: the 5D output spatial-range representation resulting from mean shift filtering\n",
    "        self.g_star = np.zeros_like(self.d)\n",
    "  \n",
    "    def d2img(self):\n",
    "        \"\"\"Compute image back from 5D space.\n",
    "        \n",
    "        Result\n",
    "        ------\n",
    "        image: np.ndarray\n",
    "            An image representing the current state of this MSS object.\n",
    "        \"\"\"\n",
    "        # just ignore the spatial coordinate and just return the color (all but the first two axis\n",
    "        # in the spatial-range representation)\n",
    "        img = self.g_star[:,2:].reshape(self.size_x, self.size_y, self.size_z) * 1/self.sigma_c\n",
    "    \n",
    "        return img/img.max()\n",
    "\n",
    "    def dist(self, p1, p2, axis=None):\n",
    "        \"\"\"Compute (euclidean) distance between points in spatial-range representation.\n",
    "        \"\"\"\n",
    "        return np.linalg.norm(p1 - p2, axis=axis)\n",
    "\n",
    "    def compute_mean_shift_step(self, point):\n",
    "        \"\"\"Perform one mean shift step by computing the center of gravity of the neighborhood\n",
    "        of the given point in the 5D spatial-range representation space.\n",
    "        \"\"\"\n",
    "        # compute 5D neighbors, a list of pixels that are within a self.radius from point\n",
    "        d_dist = self.dist(self.d, point, axis=1)\n",
    "        neighbors = self.d[d_dist<self.radius,:]\n",
    "\n",
    "        # compute the 5D gravicenter of all neighbors\n",
    "        return np.sum(neighbors, axis=0)/neighbors.shape[0]\n",
    "\n",
    "    def ms_filter(self, progress = lambda x: x):\n",
    "        \"\"\"Perform mean shift filtering as explained in CV-07, slide 100:\n",
    "        Mean shift filtering finds the local density maxima and assigns to each\n",
    "        pixel p = (s,c)T the color c* of the closest local density maximum, i.e., the\n",
    "        image g is transformed to a filtered version g* by replacing p with p*:\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        progress: function\n",
    "            A function to update a progress bar to be displayed during computation\n",
    "            (this may be useful, as computation can take some time).\n",
    "        \"\"\"\n",
    "        # loop over all pixels in 5D spatial-range representation\n",
    "        for index, point in enumerate(progress(self.d)):\n",
    "\n",
    "            # remember the original 5D coordinates of the pixel\n",
    "            point_old = point.copy()\n",
    "            delta = self.epsilon\n",
    "\n",
    "            # move point in 5D space as long as the step size is above epsilon\n",
    "            while delta >= self.epsilon:\n",
    "\n",
    "                point = self.compute_mean_shift_step(point_old)\n",
    "                delta = self.dist(point, point_old)\n",
    "                point_old = point\n",
    "\n",
    "            # store the result for this pixel\n",
    "            self.g_star[index] = point\n",
    "\n",
    "        return self.d2img()\n",
    "    \n",
    "\n",
    "    def mss_segment(self, max_dist=None, min_elem=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        max_dist: float\n",
    "            Maximal distance between pixels in 5D space to be joined\n",
    "            into a segment.\n",
    "        min_elem: int\n",
    "            Minimal number of pixels per segment. Smaller segments\n",
    "            will be merged with the \n",
    "        \"\"\"\n",
    "\n",
    "        # use default parameter values if no values are provided\n",
    "        if not min_elem: min_elem = MSS.min_elem\n",
    "        if not max_dist: max_dist = MSS.max_dist\n",
    "\n",
    "        # normalize so spatial and color are of same scale\n",
    "        max_g = self.g_star.max(axis=0)\n",
    "        g_star_norm = self.g_star.copy()/max_g\n",
    "\n",
    "        # Now perform segmentation by assigning labels to pixels.\n",
    "        # Initially, all labels are set to -1.\n",
    "        label_count = 0\n",
    "        labels = np.zeros((len(g_star_norm))) - 1\n",
    "\n",
    "        # loop over all pixels\n",
    "        for i in range(len(g_star_norm)):\n",
    "            if labels[i] == -1:  # pixel has not label yet\n",
    "                # create a new segment\n",
    "                labels[i] = label_count\n",
    "                # compute distances of unlabeled pixels to current pixels\n",
    "                dists = np.zeros_like(labels) + max_dist\n",
    "                dists[labels==-1] = np.linalg.norm(g_star_norm[labels==-1,:] - g_star_norm[i,:], axis=1)\n",
    "                # combine pixels within the given radius (max_dist) to the new segment\n",
    "                labels[dists < max_dist] = label_count\n",
    "                label_count += 1\n",
    "\n",
    "        # remove small segments\n",
    "        # compute centers in joint domain\n",
    "        centers = np.zeros((label_count, 2 + self.size_z), dtype=float)\n",
    "        for i in range(label_count):\n",
    "            mask = (labels==i)\n",
    "            centers[i] = np.sum(g_star_norm[mask], axis=0)/np.sum(mask)\n",
    "\n",
    "        # replace small segments with segments with smallest distance between segment centers\n",
    "        for i in range(label_count):\n",
    "            if np.sum(labels==i) < min_elem:\n",
    "                center = centers[i,:].copy()\n",
    "                centers[i,:] = np.inf\n",
    "\n",
    "                dist = np.linalg.norm(centers - center, axis=1)\n",
    "                labels[labels==i] = np.argmin(dist)         \n",
    "\n",
    "        # transform back to image space\n",
    "        labels_im_space = labels.reshape(self.size_x, self.size_y)\n",
    "\n",
    "        # compute mean color per segment\n",
    "        labels_colored = np.atleast_3d(np.zeros_like(img, dtype=float))\n",
    "        for i in range(label_count):\n",
    "            mask = (labels_im_space==i)\n",
    "            if np.sum(mask):\n",
    "                labels_colored[mask,:] = centers[i,2:]\n",
    "\n",
    "        labels_colored *= max_g[2:]/self.sigma_c\n",
    "        return np.squeeze(labels_colored).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc3158",
   "metadata": {},
   "source": [
    "## Demo 1\n",
    "\n",
    "Mean shift filtering and segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install `tqdm` package to display a progress bar (optional)\n",
    "!conda install -c conda-forge tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d633e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm as progress\n",
    "except ModuleNotFoundError:\n",
    "    def progress(x):\n",
    "        return x\n",
    "\n",
    "filename_image = os.path.join('images', 'peppers.png')\n",
    "# filename_image = os.path.join('images', 'burano.jpg')\n",
    "img = imread(filename_image)\n",
    "img = img[170:270,100:200]\n",
    "#img = img[500:700:2, 500:700:2]\n",
    "\n",
    "\n",
    "sigma_c = .05\n",
    "epsilon = 1\n",
    "radius = 6\n",
    "min_elem = 400\n",
    "\n",
    "mss = MSS(img, sigma_c, epsilon, radius)\n",
    "\n",
    "# perform mean shift filtering\n",
    "seg = mss.ms_filter(progress=progress)\n",
    "\n",
    "# perform mean shift segmentation\n",
    "labels = mss.mss_segment(min_elem=min_elem)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(36,12))\n",
    "plt.gray()\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(seg)\n",
    "ax3.imshow(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c5c54",
   "metadata": {},
   "source": [
    "## Demo 2\n",
    "\n",
    "Mean shift filtering with different values $\\sigma_c$ (Compare CV-6, slide 104):\n",
    "* larger $\\sigma_c$: distance in color space is more important: pixel colors should only change marginally during mean shift filtering\n",
    "* smaller $\\sigma_c$: distance in color space is less important: pixel may migrate into other \"color regions\" during mean shift filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_image = os.path.join('images', 'flower-color.png')\n",
    "img = imread(filename_image)[:,:,:3]\n",
    "\n",
    "sigma_c_1 = .04\n",
    "radius_1 = 8\n",
    "epsilon_1 = 1\n",
    "\n",
    "sigma_c_2 = .004\n",
    "radius_2 = 8\n",
    "epsilon_2 = 1\n",
    "\n",
    "sigma_c_3 = .05\n",
    "radius_3 = 6\n",
    "epsilon_3 = 1\n",
    "\n",
    "# perform mean shift filtering\n",
    "mss1 = MSS(img, sigma_c_1, epsilon_1, radius_1)\n",
    "filter1 = mss1.ms_filter(progress=progress)\n",
    "\n",
    "mss2 = MSS(img, sigma_c_2, epsilon_2, radius_2)\n",
    "filter2 = mss2.ms_filter(progress=progress)\n",
    "\n",
    "mss3 = MSS(img, sigma_c_3, epsilon_3, radius_3)\n",
    "filter3 = mss3.ms_filter(progress=progress)\n",
    "\n",
    "# output the resulting images\n",
    "fig, ax = plt.subplots(2,2, figsize=(16,10))\n",
    "plt.gray()\n",
    "ax[0,0].imshow(img); ax[0,0].set_title(\"Input\")\n",
    "ax[0,1].imshow(filter1); ax[0,1].set_title(f\"Filter 1: $\\sigma_c$={sigma_c_1:.4f}, $R$={float(radius_1):.1f}\")\n",
    "ax[1,0].imshow(filter2); ax[1,0].set_title(f\"Filter 2: $\\sigma_c$={sigma_c_2:.4f}, $R$={float(radius_2):.1f}\")\n",
    "ax[1,1].imshow(filter3); ax[1,1].set_title(f\"Filter 3: $\\sigma_c$={sigma_c_3:.4f}, $R$={float(radius_3):.1f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d8b83",
   "metadata": {},
   "source": [
    "### Mean shift segmentation\n",
    "\n",
    "Perform mean shift segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ba3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal number of pixels per segment:\n",
    "min_elem = 50\n",
    "\n",
    "# do the labeling\n",
    "labels1 = mss1.mss_segment(min_elem=min_elem)\n",
    "labels2 = mss2.mss_segment(min_elem=min_elem)\n",
    "labels3 = mss3.mss_segment(min_elem=min_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ef56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the resulting segmentation\n",
    "fig, ax = plt.subplots(2,2, figsize=(16,12))\n",
    "plt.gray()\n",
    "ax[0,0].imshow(img); ax[0,0].set_title(\"Input\")\n",
    "ax[0,1].imshow(labels1)\n",
    "ax[0,1].set_title(f\"Filter 1: $\\sigma_c$={sigma_c_1:.4f}, segments={len(np.unique(labels1))}\")\n",
    "ax[1,0].imshow(labels2)\n",
    "ax[1,0].set_title(f\"Filter 2: $\\sigma_c$={sigma_c_2:.4f}, segments={len(np.unique(labels2))}\")\n",
    "ax[1,1].imshow(labels3)\n",
    "ax[1,1].set_title(f\"Filter 2: $\\sigma_c$={sigma_c_3:.4f}, segments={len(np.unique(labels3))}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1def9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28dcc410",
   "metadata": {},
   "source": [
    "# Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166f91b",
   "metadata": {},
   "source": [
    "The following interactive matplotlib cell allows to explore the contribution of the parameters $t_1$, $t_2$ and $\\sigma$ in the canny edge detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "from imageio import imread\n",
    "from skimage import feature\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "\n",
    "sigma = 3\n",
    "t1 = .1 # .1 * max of image\n",
    "t2 = .2 # .2 * max of image\n",
    "\n",
    "img = rgb2gray(imread('../../resources/segmentation/images/murano.jpg')/255.0)\n",
    "\n",
    "def update():\n",
    "    edges = feature.canny(img, sigma=sigma, low_threshold=t1, high_threshold=t2)\n",
    "    ax2.imshow(edges, cmap='gray')\n",
    "    \n",
    "    \n",
    "def update_s(val):\n",
    "    global sigma\n",
    "    sigma = val\n",
    "    update()\n",
    "    \n",
    "    \n",
    "def update_t1(val):\n",
    "    global t1\n",
    "    t1 = val\n",
    "    update()\n",
    "    \n",
    "    \n",
    "def update_t2(val):\n",
    "    global t2\n",
    "    t2 = val\n",
    "    update() \n",
    "\n",
    "    \n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,8))\n",
    "plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "ax_s = plt.axes([0.25, 0.1, 0.65, 0.03])\n",
    "ax_t1 = plt.axes([0.25, 0.3, 0.65, 0.03])\n",
    "ax_t2 = plt.axes([0.25, 0.2, 0.65, 0.03])\n",
    "\n",
    "s_s = Slider(ax_s, 'sigma', 0, 11, valinit=3, valstep=1)\n",
    "s_s.on_changed(update_s)\n",
    "s_t1 = Slider(ax_t1, 't_1', 0, 1, valinit=.1, valstep=.05)\n",
    "s_t1.on_changed(update_t1)\n",
    "s_t2 = Slider(ax_t2, 't_2', 0, 1, valinit=.2, valstep=.05)\n",
    "s_t2.on_changed(update_t2)\n",
    "\n",
    "\n",
    "ax1.imshow(img, cmap='gray')\n",
    "update()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823042e8",
   "metadata": {},
   "source": [
    "# Matplotlib Animations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8f29b",
   "metadata": {},
   "source": [
    "Animations may help to visualize and understand the effects of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6fd2b",
   "metadata": {},
   "source": [
    "## \"Poor man's animation\"\n",
    "\n",
    "Idea: regularly update the figure:\n",
    "1. setup the figure\n",
    "2. provide a function to update the figure\n",
    "3. create a loop to run the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "img = imageio.imread('imageio:camera.png').astype(np.float32) / 255\n",
    "columns, rows = img.shape[:2]\n",
    "\n",
    "# plot the image\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1,2,1); \n",
    "plt.imshow(img, cmap='gray')\n",
    "mpl_line, = plt.plot([], [])\n",
    "\n",
    "# plot the row\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_ylim([0,1])\n",
    "ax2.set_xlim([0, columns])\n",
    "mpl_plot, = plt.plot([], [], 'b', label='image row')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b347a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_row(row):\n",
    "    mpl_line.set_data([0, columns-1], [row, row])\n",
    "    mpl_plot.set_data(np.arange(columns), img[row, :])\n",
    "    fig.canvas.draw()  # has to be called explicitly!\n",
    "\n",
    "for row in range(len(img)):\n",
    "    show_row(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231981e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The `matplotlib.anmation` module\n",
    "\n",
    "Matplotlib provides the [`animation` module](https://matplotlib.org/stable/api/animation_api.html) to create and work with animations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7db4b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To create an animation, different `Animation` classes can be used.\n",
    "* `TimedAninmation`: The `matplotlib.animation.TimedAnimation` creates an animation by displaying new frames at regular time intervals.\n",
    "* `FuncAninmation`: The `matplotlib.animation.FuncAnimation` is a subclass of the `TimedAnimation`. It creates an animation by calling a function in regular intervals to update a figure.\n",
    "* `ArtistAnimation`: The `matplotlib.animation.FuncAnimation` is a subclass of the `TimedAnimation`. It creates an animation from a sequence of MatPlotLib artists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603efd31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The `FuncAnimation` class\n",
    "\n",
    "The `FuncAnimation` takes the following arguments:\n",
    "* `func`: the function to be called to create the next frame.\n",
    "* `frames`: can be a number or an iterator. Will be passed as first argument to the update function\n",
    "* `interval`: delay between frames in milliseconds (default: 200 = 5 frames per second). A value of 40 will yield 25 frames per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c977fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import imageio\n",
    "\n",
    "img = imageio.imread('imageio:camera.png').astype(np.float32) / 255\n",
    "columns, rows = img.shape[:2]\n",
    "\n",
    "# show the image\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1,2,1); \n",
    "plt.imshow(img, cmap='gray')\n",
    "mpl_line, = plt.plot([], [])\n",
    "\n",
    "# plot the row\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_ylim([0,1])\n",
    "ax2.set_xlim([0,columns])\n",
    "mpl_plot, = plt.plot([], [], 'b', label='image row')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# animation function. This is called sequentially\n",
    "def animate(i):\n",
    "    mpl_line.set_data([0, columns-1], [i, i])\n",
    "    mpl_plot.set_data(np.arange(columns), img[i, :])\n",
    "    return [mpl_line, mpl_plot]\n",
    "\n",
    "# call the animator. blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, frames=len(img), interval=20, repeat=False, blit=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84142e6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Alternative: `ArtistAnimation`\n",
    "\n",
    "* create animation using a fixed set of Artist objects\n",
    "* for each frame a collection of Artist objects is given\n",
    "* only those artists are made visible on the corresponding frame, other artists are made invisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26deee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import imageio\n",
    "\n",
    "img = imageio.imread('imageio:camera.png').astype(np.float32) / 255\n",
    "columns, rows = img.shape[:2]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "# show the image\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "# plot the row\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_ylim([0,1])\n",
    "\n",
    "# create a list of artists collections\n",
    "frames = []\n",
    "for row in range(rows):\n",
    "    plt.subplot(1,2,1)\n",
    "    mpl_line, = ax1.plot([0, columns-1], [row, row], 'b')\n",
    "    plt.subplot(1,2,2)\n",
    "    mpl_plot, = ax2.plot(np.arange(columns), img[row, :], 'b', label='image row')\n",
    "    frames.append([mpl_line, mpl_plot])\n",
    "\n",
    "anim = animation.ArtistAnimation(fig, frames, interval=20, repeat=False, blit=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a5185",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Showing animations in the notebook: `to_html5_video()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1ec08",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(anim.to_html5_video())  # this may need some time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370c15d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Storing animations: `anim.save`\n",
    "\n",
    "* animation can be stored in different formats\n",
    "* various parameters can be passed to adapt the output (see [documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.animation.Animation.html#matplotlib.animation.Animation.save))\n",
    "* different backends can be used (may have to be installed separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save('anim.mp4', fps=20)  # this may need some time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d71f66",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"anim.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3df31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Efficiency: Python vs Numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5779f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The (average) Runtime of a function can be measured with the `%timeit` magic command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e55a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "L = range(2000)\n",
    "\n",
    "%timeit [i**2 for i in L]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb2760",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `timeit` library:\n",
    "* loops: calls the command repeatedly and measures the the (average) execution time\n",
    "* the number of loops is automatically choosen according to the execution time\n",
    "* multiple runs: `timeit` usually runs this measurement multiple times\n",
    "* the parameters `-r` (number of runs) and `-n` (loops per run) can be used to controll these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a065e80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "L = range(2000)\n",
    "%timeit -r 3 -n 20 [i**2 for i in L]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744296b",
   "metadata": {},
   "source": [
    "Changing the function may speed up processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79170e69",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "%timeit -r 3 -n 1000 [math.pow(i,2) for i in L]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cb9e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparison of pure Python and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadeb310",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "L = range(2000)\n",
    "a = np.arange(2000)\n",
    "\n",
    "%timeit [i*2 for i in L]\n",
    "%timeit a*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b42ad73",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using numpy operators is usually **much** faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ab2c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example: Matrix sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum1(a, b, result):\n",
    "    for i in np.ndindex(a.shape):\n",
    "        result[i] = a[i] + b[i]\n",
    "\n",
    "def sum2(a, b, result):\n",
    "    result[:] = a + b\n",
    "\n",
    "n = 1000\n",
    "a = np.random.rand(n,n)\n",
    "b = np.random.rand(*a.shape)\n",
    "result = np.ndarray(a.shape)\n",
    "\n",
    "%timeit sum1(a, b, result)\n",
    "%timeit sum2(a, b, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f85f91",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Try to use **vectorized computation** (avoid loops)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f98cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Task:** Find out what the following function do. The try to vectorize the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b46d965",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3d35a0e42ddd6a07",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func1bad(a, b, result):\n",
    "    for i in np.ndindex(a.shape):\n",
    "        d = a[i]**2 + b[i]**2\n",
    "        result[i] = np.sqrt(d)\n",
    "\n",
    "def func1good(a, b, result):\n",
    "    # BEGIN SOLUTION\n",
    "    result[:] = np.sqrt(a**2 + b**2)\n",
    "    # END SOLUTION\n",
    "    \n",
    "n = 1000\n",
    "a = np.random.rand(n,n)\n",
    "b = np.random.rand(*a.shape)\n",
    "result = np.ndarray(a.shape)\n",
    "\n",
    "%timeit func1bad(a, b, result)\n",
    "%timeit func1good(a, b, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3747a",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6e1030e7d750347e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func2bad(img, threshold):\n",
    "    for i in np.ndindex(img.shape):\n",
    "        if img[i] < threshold:\n",
    "            img[i] = 0\n",
    "\n",
    "def func2good(img, threshold):\n",
    "    # BEGIN SOLUTION\n",
    "    img[img<threshold] = 0\n",
    "    # END SOLUTION\n",
    "\n",
    "n = 1000\n",
    "threshold = .7\n",
    "img1 = np.random.rand(n,n)\n",
    "img2 = img1.copy()\n",
    "\n",
    "%timeit func2bad(img1, threshold)\n",
    "%timeit func2good(img2, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357dd00",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c1581898906d5ec3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func3bad(a, b, result):\n",
    "    assert a.shape[1] == b.shape[0]\n",
    "    for i,j in np.ndindex(result.shape):\n",
    "        result[i,j] = 0\n",
    "        for k in np.arange(a.shape[1]):\n",
    "            result[i,j] += a[i,k] * b[k,j]\n",
    "\n",
    "def func3good(a, b, result):\n",
    "    # BEGIN SOLUTION\n",
    "    result[:] = a @ b\n",
    "    # END SOLUTION\n",
    "\n",
    "n = 100\n",
    "a = np.random.rand(n,n)\n",
    "b = np.random.rand(*a.shape)\n",
    "result = np.ndarray(a.shape)\n",
    "\n",
    "%timeit func3bad(a, b, result)\n",
    "%timeit func3good(a, b, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee9ff1",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-22ff457af42acb70",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func4(edges, result):\n",
    "    for row,col in np.ndindex(result.shape):\n",
    "        result[row,col] = False\n",
    "        if (((edges[row,col] > 0) and (edges[row,col+1] < 0)) or\n",
    "            ((edges[row,col] < 0) and (edges[row,col+1] > 0))):\n",
    "            result[row,col] = True\n",
    "        elif (((edges[row,col] > 0) and (edges[row+1,col] < 0)) or\n",
    "            ((edges[row,col] < 0) and (edges[row+1,col] > 0))):\n",
    "            result[row,col] = True\n",
    "\n",
    "def func4vector(edges, result):\n",
    "    # BEGIN SOLUTION\n",
    "    result[:] = (edges[:-1, 1:] * edges[1:, 1:] <= 0) | (edges[1:, :-1] * edges[1:, 1:] <= 0)\n",
    "    \n",
    "def func4vector_bad(edges, result):\n",
    "    # The following is not really faster, in fact it is much slower!\n",
    "    \n",
    "    result[:] = (np.logical_and(edges[:-1, 1:]<0.,edges[1:, 1:]>0.) |\n",
    "                 np.logical_and(edges[:-1, 1:]>0.,edges[1:, 1:]<0.) |\n",
    "                 np.logical_and(edges[1:, :-1]<0.,edges[1:, 1:]>0.) |\n",
    "                 np.logical_and(edges[1:, :-1]>0.,edges[1:, 1:]<0.))\n",
    "    # END SOLUTION\n",
    "\n",
    "n = 1000\n",
    "edges = np.random.randn(n,n)\n",
    "result = np.ndarray((edges.shape[0]-1,edges.shape[1]-1), dtype=bool)\n",
    "\n",
    "%timeit func4(edges, result)\n",
    "%timeit func4vector(edges, result)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
